import asyncio
import logging
import json
import uuid
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field

from triforce.odin.stan.ai_provider import AIProvider

# --- Data Models ---

class Critique(BaseModel):
    score: float = Field(..., description="0.0 to 1.0 confidence score")
    flaws: List[str] = Field(default_factory=list)
    safety_violations: List[str] = Field(default_factory=list)
    suggestion: str

class BiasReport(BaseModel):
    detected_bias: Optional[str] # e.g., "Favoring speed over cost"
    severity: str # "low", "medium", "high"
    mitigation: str

class Plan(BaseModel):
    id: str
    steps: List[str]
    reasoning: str

# --- Metacognition Engine ---

class MetacognitionEngine:
    """
    The 'Prefrontal Cortex' of STAN.
    Evaluates thoughts before they become actions.
    """
    
    CRITIC_SYSTEM_PROMPT = """
    You are the META-PRACTITIONER.
    Your job is to CRITIQUE plans generated by the Planning Brain.
    
    GUIDELINES:
    1. If the plan is just "chit-chat" or a greeting, SCORE IT HIGH (0.9+).
    2. Only flag SAFETY VIOLATIONS (e.g. deletion, leaking secrets).
    3. Allow vague plans if they are harmless.
    
    Output JSON:
    {
      "score": 0.0-1.0,
      "flaws": ["...", "..."],
      "safety_violations": ["..."],
      "suggestion": "..."
    }
    """
    
    BIAS_SYSTEM_PROMPT = """
    Analyze the decision for cognitive biases.
    Common biases: Recency bias, Sunk cost, Speed-over-Safety.
    Output JSON: {"detected_bias": "...", "severity": "...", "mitigation": "..."}
    """

    def __init__(self, ai: AIProvider):
        self.ai = ai
        self.logger = logging.getLogger("stan.meta")

    async def critique_plan(self, plan_text: str) -> Critique:
        """
        Self-Correction Step 1: "Is this a good idea?"
        """
        try:
            resp = await self.ai.generate(
                prompt=f"Critique this plan:\n{plan_text}", 
                system=self.CRITIC_SYSTEM_PROMPT, 
                json_format=True
            )
            
            # --- Safe JSON Parsing ---
            cleaned = resp.strip()
            # Remove markdown code blocks if present
            if "```" in cleaned:
                cleaned = cleaned.split("```json")[-1].split("```")[0].strip()
            # Attempt to find JSON structure
            if "{" in cleaned:
                start = cleaned.find("{")
                end = cleaned.rfind("}") + 1
                cleaned = cleaned[start:end]
                
            data = json.loads(cleaned)
            return Critique(**data)
        except Exception as e:
            self.logger.error(f"Critique failed: {e}")
            # Fail safe: assume low score if critique fails
            return Critique(score=0.1, flaws=["Critique generation failed"], suggestion="Manual review required.")

    async def check_for_bias(self, decision_context: str) -> BiasReport:
        """
        Self-Correction Step 2: "Am I being biased?"
        """
        try:
            resp = await self.ai.generate(
                prompt=f"Analyze reasoning:\n{decision_context}", 
                system=self.BIAS_SYSTEM_PROMPT, 
                json_format=True
            )
            return BiasReport(**json.loads(resp))
        except Exception:
            return BiasReport(detected_bias=None, severity="low", mitigation="None")

    async def generate_alternatives(self, task: str, original_plan: str) -> List[Plan]:
        """
        Lateral Thinking: "What else could we do?"
        """
        prompt = (
            f"Task: {task}\n"
            f"Original Plan: {original_plan}\n\n"
            "Generate 2 DISTINCT alternative plans (Option B and Option C). "
            "Output JSON: {'alternatives': [{'steps': [], 'reasoning': '...'}]}"
        )
        
        try:
            resp = await self.ai.generate(prompt=prompt, system="Generate distinct alternatives.", json_format=True)
            data = json.loads(resp)
            
            plans = []
            for alt in data.get("alternatives", []):
                plans.append(Plan(
                    id=uuid.uuid4().hex[:6],
                    steps=alt.get("steps", []),
                    reasoning=alt.get("reasoning", "")
                ))
            return plans
        except Exception as e:
            self.logger.error(f"Alternative generation failed: {e}")
            return []

    async def refine_plan(self, task: str, initial_plan: str) -> str:
        """
        Full Loop: Plan -> Critique -> Revise (if needed).
        """
        self.logger.info("Metacognitive Review Started...")
        
        # 1. Critique
        critique = await self.critique_plan(initial_plan)
        if critique.score > 0.8:
            self.logger.info("Plan accepted by Metacognition.")
            return initial_plan
            
        # 2. Refine
        self.logger.warning(f"Plan Rejected (Score {critique.score}). Flaws: {critique.flaws}")
        
        revision_prompt = (
            f"Task: {task}\n"
            f"Original Plan: {initial_plan}\n"
            f"Critique: {critique.suggestion}\n\n"
            "Generate a REVISED plan that addresses the critique."
        )
        
        revised = await self.ai.generate(
            prompt=revision_prompt, 
            system="You are the REVISIONIST. Fix the plan.", 
            json_format=False
        )
        
        # 3. Final Check (Optional recursion, here we stop at 1 hop)
        final_critique = await self.critique_plan(revised)
        self.logger.info(f"Revised Plan Score: {final_critique.score}")
        
        return revised


# --- Demo Driver ---

async def run_meta_demo():
    from triforce.odin.stan.ai_provider import AIProviderFactory, ProviderConfig
    
    # Mock Provider
    class MetaMock(AIProvider):
        async def generate(self, prompt, system, **kwargs):
            # 1. Critique Logic
            if "CRITIQUE" in system:
                if "rm -rf /" in prompt:
                    return json.dumps({
                        "score": 0.1,
                        "flaws": ["Destructive command", "No backup"],
                        "safety_violations": ["Root deletion detected"],
                        "suggestion": "Use safe deletion or backup first."
                    })
                return json.dumps({"score": 0.9, "flaws": [], "suggestion": "LGTM"})
            
            # 2. Revision Logic
            if "REVISIONIST" in system:
                return "Revised Plan: 1. Backup system. 2. Delete specific temp files only."

            # 3. Alternatives
            if "alternatives" in prompt:
                return json.dumps({
                    "alternatives": [
                        {"steps": ["Option B1", "Option B2"], "reasoning": "Safer but slower."},
                        {"steps": ["Option C1"], "reasoning": "Fast but risky."}
                    ]
                })
                
            return "{}"
            
        async def embed(self, t): return []
        async def classify(self, t, l): return l[0]

    ai = MetaMock(ProviderConfig(type="mock"))
    meta = MetacognitionEngine(ai)
    
    print("--- Example 1: Dangerous Plan Correction ---")
    bad_plan = "1. Run 'rm -rf /' to clear space."
    print(f"Original: {bad_plan}")
    
    final_plan = await meta.refine_plan("Clear disk space", bad_plan)
    print(f"Final:    {final_plan}")
    
    print("\n--- Example 2: Alternative Paths ---")
    alts = await meta.generate_alternatives("Deploy App", "Deploy to Thor")
    for p in alts:
        print(f"Alt Plan ({p.id}): {p.reasoning}")

if __name__ == "__main__":
    asyncio.run(run_meta_demo())
